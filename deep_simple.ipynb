{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb2e82931b0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = torch.Size([710, 1, 1, 300, 300])\n",
      "X_real shape = torch.Size([160, 1, 1, 300, 300])\n",
      "X_frozen shape = torch.Size([100, 1, 1, 300, 300])\n"
     ]
    }
   ],
   "source": [
    "def crop(X):\n",
    "    res = np.zeros((len(X), len(X[0]), 300, 300))\n",
    "    for p in range(len(X)):\n",
    "        for s in range(len(X[p])):\n",
    "            for i in range(106, 406):\n",
    "                res[p][s][i - 106] = X[p][s][i][106:406]\n",
    "    return res\n",
    "\n",
    "# MRIs\n",
    "X = np.load('small_data.npy')\n",
    "X = crop(X)\n",
    "\n",
    "\n",
    "# labels\n",
    "y = pd.read_csv('all_target.csv')\n",
    "y.columns = ['y']\n",
    "\n",
    "# devide into 2 classes: no cut / cut - (0 / 1)\n",
    "y = np.where(y.y <= 3, 0, 1)\n",
    "\n",
    "\n",
    "# Find all ill and healthy indeces\n",
    "ill_inds = np.argwhere(y==1).flatten()\n",
    "hea_inds = np.argwhere(y==0).flatten()\n",
    "\n",
    "# Choose 5 from each group for further testing \n",
    "ill_test_inds = np.random.choice(ill_inds, 5, replace=False)\n",
    "hea_test_inds = np.random.choice(hea_inds, 5, replace=False)\n",
    "\n",
    "test_inds = [*ill_test_inds, *hea_test_inds]\n",
    "train_inds = [i for i in range(len(y)) if i not in test_inds]\n",
    "\n",
    "X_frozen = X[test_inds]\n",
    "y_frozen = y[test_inds]\n",
    "\n",
    "# Save just original balanced\n",
    "real_ill_train = np.array([i for i in ill_inds if i not in ill_test_inds])\n",
    "real_hea_train = np.random.choice([i for i in hea_inds if i not in hea_test_inds],\n",
    "                                  len(real_ill_train), replace=False)\n",
    "\n",
    "real_inds = []\n",
    "for i in range(len(real_ill_train)):\n",
    "    real_inds.append(real_ill_train[i])\n",
    "    real_inds.append(real_hea_train[i])\n",
    "\n",
    "X_real = X[real_inds]\n",
    "y_real = y[real_inds]\n",
    "\n",
    "# leave the rest and use as the main data\n",
    "X = X[train_inds]\n",
    "y = y[train_inds]\n",
    "\n",
    "# Transformation\n",
    "X = torch.from_numpy(X).to(torch.float32).reshape((710, 1, 1, 300, 300))\n",
    "y = [[i]*10 for i in y]\n",
    "y = torch.tensor(y).to(torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_frozen = torch.from_numpy(X_frozen).to(torch.float32).reshape((100, 1, 1, 300, 300))\n",
    "y_frozen = [[i]*10 for i in y_frozen]\n",
    "y_frozen = torch.tensor(y_frozen).to(torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_real = torch.from_numpy(X_real).to(torch.float32).reshape((160, 1, 1, 300, 300))\n",
    "y_real = [[i]*10 for i in y_real]\n",
    "y_real = torch.tensor(y_real).reshape(-1, 1)\n",
    "\n",
    "new_inds = []\n",
    "for i in range(10):\n",
    "    for j in range(i, 160, 10):\n",
    "        new_inds.append(j)\n",
    "\n",
    "X_real = X_real[new_inds]\n",
    "y_real = y_real[new_inds]\n",
    "\n",
    "print(f'X shape = {X.shape}')\n",
    "print(f'X_real shape = {X_real.shape}')\n",
    "print(f'X_frozen shape = {X_frozen.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_simple(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=28, kernel_size=5),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.class_layers = nn.Sequential(\n",
    "            nn.Linear(28*144*144, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.Linear(500, 100),\n",
    "            nn.Linear(100, 10),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.class_layers(x.reshape((self.batch_size, -1, 28*144*144)))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 144, 144])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0750, -0.2078]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = deep_simple(1)\n",
    "ds(X_real[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7004396.0\n",
      "Loss: 22410.0484\n",
      "Loss: 30158.025\n",
      "Loss: 17417.0297\n",
      "Loss: 3664.8367\n",
      "Loss: 12491.407\n",
      "Loss: 2538.0125\n",
      "Loss: 923.3652\n",
      "Loss: 1139.7498\n",
      "Loss: 798.8555\n",
      "Loss: 368.672\n",
      "Loss: 178.0038\n",
      "Loss: 192.7193\n",
      "Loss: 247.5324\n",
      "Loss: 175.038\n",
      "Loss: 192.4241\n",
      "Epochs passed: 0, \t Frozen Accuracy: 0.53\n",
      "[[26 23]\n",
      " [24 27]]\n",
      "Loss: 123.8772\n",
      "Loss: 244.8015\n",
      "Loss: 30.869\n",
      "Loss: 261.3204\n",
      "Loss: 49.4534\n",
      "Loss: 0.0\n",
      "Loss: 99.4896\n",
      "Loss: 50.364\n",
      "Loss: 183.672\n",
      "Loss: 171.8393\n",
      "Loss: 148.2712\n",
      "Loss: 124.401\n",
      "Loss: 148.0999\n",
      "Loss: 70.2467\n",
      "Loss: 99.3141\n",
      "Loss: 146.6992\n",
      "Epochs passed: 1, \t Frozen Accuracy: 0.56\n",
      "[[35 29]\n",
      " [15 21]]\n",
      "Loss: 65.18\n",
      "Loss: 35.8452\n",
      "Loss: 45.734\n",
      "Loss: 36.9794\n",
      "Loss: 24.9572\n",
      "Loss: 33.3329\n",
      "Loss: 0.0\n",
      "Loss: 0.3978\n",
      "Loss: 1.9328\n",
      "Loss: 0.0\n",
      "Loss: 6.8776\n",
      "Loss: 25.3305\n",
      "Loss: 12.3646\n",
      "Loss: 43.478\n",
      "Loss: 16.2007\n",
      "Loss: 33.2071\n",
      "Epochs passed: 2, \t Frozen Accuracy: 0.58\n",
      "[[23 15]\n",
      " [27 35]]\n",
      "Loss: 49.9366\n",
      "Loss: 8.7303\n",
      "Loss: 45.8703\n",
      "Loss: 60.2665\n",
      "Loss: 21.3747\n",
      "Loss: 15.9647\n",
      "Loss: 47.6371\n",
      "Loss: 141.3612\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 11.9449\n",
      "Loss: 22.0871\n",
      "Loss: 47.4042\n",
      "Loss: 11.9059\n",
      "Loss: 6.4046\n",
      "Loss: 12.2015\n",
      "Epochs passed: 3, \t Frozen Accuracy: 0.51\n",
      "[[32 31]\n",
      " [18 19]]\n",
      "Loss: 0.0\n",
      "Loss: 14.816\n",
      "Loss: 6.4491\n",
      "Loss: 0.4396\n",
      "Loss: 7.7799\n",
      "Loss: 0.0\n",
      "Loss: 10.9413\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 26.6781\n",
      "Loss: 5.6094\n",
      "Loss: 0.0\n",
      "Loss: 15.7352\n",
      "Loss: 1.9363\n",
      "Loss: 8.912\n",
      "Loss: 13.212\n",
      "Epochs passed: 4, \t Frozen Accuracy: 0.5\n",
      "[[22 22]\n",
      " [28 28]]\n",
      "Loss: 18.1077\n",
      "Loss: 9.837\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 2.9973\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.3441\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 17.3841\n",
      "Loss: 39.7418\n",
      "Epochs passed: 5, \t Frozen Accuracy: 0.53\n",
      "[[24 21]\n",
      " [26 29]]\n",
      "Loss: 30.0067\n",
      "Loss: 0.0\n",
      "Loss: 9.6098\n",
      "Loss: 9.8638\n",
      "Loss: 0.0\n",
      "Loss: 2.8797\n",
      "Loss: 23.8449\n",
      "Loss: 0.0\n",
      "Loss: 0.0598\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 6.4307\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Epochs passed: 6, \t Frozen Accuracy: 0.53\n",
      "[[26 23]\n",
      " [24 27]]\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 2.072\n",
      "Loss: 0.0\n",
      "Loss: 0.0338\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 18.726\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Epochs passed: 7, \t Frozen Accuracy: 0.54\n",
      "[[14 10]\n",
      " [36 40]]\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 2.2658\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 1.6328\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Epochs passed: 8, \t Frozen Accuracy: 0.56\n",
      "[[27 21]\n",
      " [23 29]]\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Epochs passed: 9, \t Frozen Accuracy: 0.56\n",
      "[[27 21]\n",
      " [23 29]]\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n",
      "Epochs passed: 10, \t Frozen Accuracy: 0.56\n",
      "[[27 21]\n",
      " [23 29]]\n",
      "Loss: 0.0\n",
      "Loss: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-1ca52d8651ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Load a pretrained model\n",
    "ds = deep_simple(1)\n",
    "# ds.load_state_dict(torch.load('deep_simple_dict.pth'))\n",
    "# ds.eval()\n",
    "# print('Model is loaded')\n",
    "\n",
    "# Real data training and testing\n",
    "# training\n",
    "n_epoch = 20\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(ds.parameters(), lr=0.01)\n",
    "\n",
    "best_acc = 0.5\n",
    "mod_cnt = 1\n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    i_cnt = 0\n",
    "    loss_sum = 0\n",
    "    for i, sample in enumerate(X_real):\n",
    "        preds = ds(sample).reshape(-1, 2)\n",
    "        lable = y_real[i]\n",
    "        \n",
    "        loss = criterion(preds, lable)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        i_cnt += 1\n",
    "        loss_sum += loss\n",
    "        \n",
    "        if i_cnt == 10:\n",
    "            print(f'Loss: {round(loss_sum.item() / 10, 4)}')\n",
    "            i_cnt = 0\n",
    "            loss_sum = 0\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "        for j, samp in enumerate(X_frozen):\n",
    "            preds = torch.argmax(ds(samp).reshape(-1, 2)).item()\n",
    "            lable = y_frozen[j].item()\n",
    "\n",
    "            if preds == lable:\n",
    "                if lable == 1:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    tn += 1\n",
    "\n",
    "            else:\n",
    "                if lable == 1:\n",
    "                    fn += 1\n",
    "                else:\n",
    "                    fp += 1\n",
    "\n",
    "        acc = (tp + tn) / len(y_frozen)\n",
    "        print(f'Epochs passed: {epoch}, \\t Frozen Accuracy: {acc}')\n",
    "        print(f'{np.array([[tp, fp], [fn, tn]])}')\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(ds.state_dict(), f'ds_{mod_cnt}_dict.pth')\n",
    "            mod_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
