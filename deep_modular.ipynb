{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def crop(X):\n",
    "    res = np.zeros((len(X), len(X[0]), 300, 300))\n",
    "    for p in range(len(X)):\n",
    "        for s in range(len(X[p])):\n",
    "            for i in range(106, 406):\n",
    "                res[p][s][i - 106] = X[p][s][i][106:406]\n",
    "    return res\n",
    "\n",
    "\n",
    "# MRIs\n",
    "X = np.load('small_data.npy')\n",
    "X = crop(X)\n",
    "\n",
    "\n",
    "# labels\n",
    "y = pd.read_csv('all_target.csv')\n",
    "y.columns = ['y']\n",
    "\n",
    "# devide into 2 classes: cut / no cut\n",
    "y = np.where(y.y < 3, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave 22% of entire patient MRI sets untouched for testing\n",
    "\n",
    "18 of 81 patients (9 from each group) are removed in order to test the multi-modular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (63, 10, 300, 300)\n"
     ]
    }
   ],
   "source": [
    "# Find all ill and healthy indeces\n",
    "ill_inds = np.argwhere(y==0).flatten()\n",
    "hea_inds = np.argwhere(y==1).flatten()\n",
    "\n",
    "# Choose 9 from each group for further testing \n",
    "ill_test_inds = np.random.choice(ill_inds, 9, replace=False)\n",
    "hea_test_inds = np.random.choice(hea_inds, 9, replace=False)\n",
    "\n",
    "test_inds = [*ill_test_inds, *hea_test_inds]\n",
    "train_inds = [i for i in range(len(y)) if i not in test_inds]\n",
    "\n",
    "X_TEST = X[test_inds]\n",
    "Y_TEST = y[test_inds]\n",
    "\n",
    "# leaave the rest and use main data\n",
    "X = X[train_inds]\n",
    "y = y[train_inds]\n",
    "\n",
    "print(f'X shape = {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([13, 50]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "X_temp = X.reshape((630, -1))\n",
    "y_temp = np.array([[i]*10 for i in y]).reshape((630, -1))\n",
    "\n",
    "X_smote, y_smote = sm.fit_resample(X_temp, y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([500, 500]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_smote, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts in test data: (array([0, 1]), array([158, 172]))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_smote, y_smote, test_size=0.33, random_state=42)\n",
    "\n",
    "# count classes\n",
    "print(f'Class counts in test data: {np.unique(y_test, return_counts=True)}')\n",
    "\n",
    "# From numpy to torch\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "X_TEST = torch.from_numpy(X_TEST)\n",
    "Y_TEST = torch.from_numpy(Y_TEST)\n",
    "X_TEST = X_TEST.to(torch.float32)\n",
    "\n",
    "# Reshaping\n",
    "X_train = X_train.unsqueeze(1).reshape((670, 1, 300, 300))\n",
    "X_test = X_test.unsqueeze(1).reshape((330, 1, 300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Part 1: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_simple(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.class_layers = nn.Sequential(\n",
    "            nn.Linear(341056, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 100),\n",
    "            nn.Linear(100, 10),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "#         print(x.shape)\n",
    "        x = self.class_layers(x.reshape((self.batch_size, -1, 341056)))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([347, 323]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Batches\n",
    "batch_size = 10\n",
    "\n",
    "# X_train\n",
    "X_train_loader = torch.utils.data.DataLoader(\n",
    "    X_train,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# y_train\n",
    "y_train_loader = torch.utils.data.DataLoader(\n",
    "    y_train,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "ds = deep_simple(batch_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(ds.parameters(), lr=0.01)\n",
    "\n",
    "n_epochs = 6\n",
    "last_acc = 0.\n",
    "mmds_cnt = 1\n",
    "best_res = 0.778\n",
    "for n in range(n_epochs):\n",
    "    break\n",
    "    # training\n",
    "    y_train_iter = iter(y_train_loader)\n",
    "    cnt_5 = 0\n",
    "    loss_cnt = 0\n",
    "    for sample in X_train_loader:\n",
    "    \n",
    "        labels = next(y_train_iter)\n",
    "        preds = ds(sample.to(torch.float32)).view(batch_size, 2)\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        cnt_5 += 1\n",
    "        if cnt_5 == 11:\n",
    "            print(f'loss = {round(loss.item(), 4)}')\n",
    "            cnt_5 = 0\n",
    "        \n",
    "        \n",
    "        loss_cnt += int(loss < 0.01)\n",
    "        \n",
    "    # testing real patients\n",
    "    res = MMDS(ds, X_TEST, Y_TEST)\n",
    "    print(f'TEST ACCURACY: {res}')\n",
    "    if res > best_res:\n",
    "        torch.save(ds.state_dict(), f'MMDS_{mmds_cnt}_dict.pth')\n",
    "        mmds_cnt += 1\n",
    "        best_res = res\n",
    "        print(f'BEST MMDS TEST ACCURACY: {res}')\n",
    "    \n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        test_preds = ds(X_test.to(torch.float32)).reshape((330, -1))\n",
    "        cnt = 0\n",
    "        for i, pred in enumerate(test_preds):\n",
    "            cnt += torch.argmax(pred) == y_test[i]\n",
    "\n",
    "        acc = cnt / 390\n",
    "        print(f'E{n+1}  Accuracy = {round(acc.item(), 5)}')\n",
    "    \n",
    "    if torch.abs(acc - last_acc) < 0.000005:\n",
    "        break\n",
    "    last_acc = acc\n",
    "    \n",
    "#     if loss_cnt > 20:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_iter = iter(y_train_loader)\n",
    "next(y_train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Part 2: Multi-Modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Modular Deep-Simple\n",
    "def MMDS(model, X, y, batch_size=10, return_res=False):\n",
    "    X = X.unsqueeze(2)\n",
    "    print(X.shape)\n",
    "    n = len(y)\n",
    "    acc = 0\n",
    "    res = []\n",
    "    for i, x in enumerate(X):\n",
    "        out = model(x).reshape(batch_size, 2)\n",
    "        out = torch.argmax(out, dim=1).sum().item()\n",
    "        pred = int(out > 5)\n",
    "        res.append(pred)\n",
    "        \n",
    "        acc += (pred == y[i])\n",
    "    \n",
    "    acc = (acc / n).item()\n",
    "    \n",
    "    if return_res:\n",
    "        return (res, acc)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MMDS(ds, X_TEST, Y_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(ds.state_dict(), 'MMDS_0_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6e1a8dd2aa49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mds_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MMDS_0_dict.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mds_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "ds_m = deep_simple(batch_size)\n",
    "ds_m.load_state_dict(torch.load('MMDS_0_dict.pth'))\n",
    "ds_m.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class deep_mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.class_layer = nn.Sequential(\n",
    "            nn.Linear(10, 1000),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.Linear(1000, 100),\n",
    "            nn.Linear(100, 10),\n",
    "            nn.Linear(10, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.class_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).to(torch.float32)\n",
    "y = torch.from_numpy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t avg loss: 5.955\ttrain acc: 0.9841\ttest acc: 0.7778\n",
      "Epoch: 2\t avg loss: 2.3636\ttrain acc: 0.9841\ttest acc: 0.7222\n",
      "Epoch: 3\t avg loss: 102.4059\ttrain acc: 0.873\ttest acc: 0.7222\n",
      "Epoch: 4\t avg loss: 56.4246\ttrain acc: 0.9524\ttest acc: 0.6667\n",
      "Epoch: 5\t avg loss: 44.7792\ttrain acc: 0.9841\ttest acc: 0.7778\n",
      "Epoch: 6\t avg loss: 284.65\ttrain acc: 0.9683\ttest acc: 0.7778\n",
      "Epoch: 7\t avg loss: 241.5045\ttrain acc: 0.9841\ttest acc: 0.7778\n",
      "Epoch: 8\t avg loss: 7.2524\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 9\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 10\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 11\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 12\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 13\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 14\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 15\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 16\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 17\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 18\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 19\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n",
      "Epoch: 20\t avg loss: 0.0\ttrain acc: 1.0\ttest acc: 0.7222\n"
     ]
    }
   ],
   "source": [
    "ds = deep_simple(batch_size)\n",
    "ds.load_state_dict(torch.load('full_MMDS_p1_dict.pth'))\n",
    "ds.eval()\n",
    "\n",
    "dm = deep_mod()\n",
    "dm.load_state_dict(torch.load('full_MMDS_p2_dict.pth'))\n",
    "dm.eval()\n",
    "\n",
    "best_acc = 0.84\n",
    "optim = torch.optim.Adam(dm.parameters(), lr=0.008)\n",
    "mod_cnt = 2\n",
    "for epoch in range(20):\n",
    "    print(f'Epoch: {epoch+1}\\t avg loss:', end = ' ')\n",
    "    losses = []\n",
    "    for i, x in enumerate(X.unsqueeze(2)):\n",
    "        pat = ds(x)\n",
    "        pat = pat.reshape(10, 2).argmax(axis=1)\n",
    "        pat = pat.reshape(-1, 10).to(torch.float32)\n",
    "        res = dm(pat)\n",
    "        label = y[i].flatten()\n",
    "        loss = criterion(res, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "    print(round(np.mean(losses), 4), end = '\\t')\n",
    "    \n",
    "    #TRAIN\n",
    "    acc = 0\n",
    "    c = 0\n",
    "    for i, x in enumerate(X.unsqueeze(2)):\n",
    "        pat = ds(x)\n",
    "        pat = pat.reshape(10, 2).argmax(axis=1)\n",
    "        pat = pat.reshape(-1, 10).to(torch.float32)\n",
    "        res = dm(pat).flatten().argmax()\n",
    "        label = y[i].flatten()\n",
    "        acc += (res == label[0])\n",
    "        c += 1\n",
    "    acc = round(acc.item()/c, 4)\n",
    "    print(f'train acc: {acc}', end = '\\t')\n",
    "        \n",
    "    # TEST\n",
    "    acc = 0\n",
    "    for i, x in enumerate(X_TEST.unsqueeze(2).to(torch.float32)):\n",
    "        pat = ds_m(x)\n",
    "        pat = pat.reshape(10, 2).argmax(axis=1)\n",
    "        pat = pat.reshape(-1, 10).to(torch.float32)\n",
    "        res = dm(pat).flatten().argmax()\n",
    "        label = Y_TEST[i].flatten()\n",
    "        # print(res, label[0])\n",
    "        acc += (res == label[0])\n",
    "    acc = round(acc.item()/18, 4)\n",
    "    print(f'test acc: {acc}')\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        print(f'\\t \\t MAX !!!')\n",
    "        torch.save(dm.state_dict(), f'full_{mod_cnt}_MMDS_p2_dict.pth')\n",
    "        mod_cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(ds_m.state_dict(), 'full_MMDS_p1_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(dm.state_dict(), 'full_MMDS_p2_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deep_mod(\n",
       "  (class_layer): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=1000, bias=True)\n",
       "    (1): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    (2): Linear(in_features=1000, out_features=100, bias=True)\n",
       "    (3): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (4): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = deep_simple(batch_size)\n",
    "ds.load_state_dict(torch.load('full_MMDS_p1_dict.pth'))\n",
    "ds.eval()\n",
    "\n",
    "dm = deep_mod()\n",
    "dm.load_state_dict(torch.load('full_MMDS_p2_dict.pth'))\n",
    "dm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i, x in enumerate(X_TEST.unsqueeze(2).to(torch.float32)):\n",
    "    pat = ds_m(x)\n",
    "    pat = pat.reshape(10, 2).argmax(axis=1)\n",
    "    pat = pat.reshape(-1, 10).to(torch.float32)\n",
    "    res = dm(pat).flatten().argmax()\n",
    "    label = Y_TEST[i].flatten()\n",
    "    # print(res, label[0])\n",
    "    acc += (res == label[0])\n",
    "print(f'test acc: {acc/18}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing prelearnt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 10, 1, 300, 300])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds0 = deep_simple(10)\n",
    "ds0.load_state_dict(torch.load('deep_simple_dict.pth'))\n",
    "ds0.eval()\n",
    "\n",
    "MMDS(ds0, X_TEST, Y_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
